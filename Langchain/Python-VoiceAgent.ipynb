{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be26e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import requests\n",
    "import tempfile\n",
    "import webrtcvad\n",
    "import time\n",
    "import subprocess\n",
    "import threading\n",
    "import sys\n",
    "\n",
    "# Constants\n",
    "OPENAI_API_KEY = \"your-openai-api-key\" \n",
    "ELEVEN_LABS_API_KEY = \"your-eleven-labs-api-key\"  \n",
    "VOICE_ID = \"your-voice-id\" \n",
    "MODEL_ID = \"eleven_monolingual_v1\" # you can add any model here \n",
    "ENABLE_TTS = True\n",
    "MAX_TTS_CHARACTERS = 250\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "stop_playback = threading.Event()\n",
    "tts_active = threading.Event()\n",
    "\n",
    "def elevenlabs_stream_tts(text, fs=16000):\n",
    "    \"\"\"\n",
    "    Streams ElevenLabs TTS audio in small chunks, allowing immediate interruption.\n",
    "    Returns True if playback was interrupted by user speech.\n",
    "    \"\"\"\n",
    "    global stop_playback, tts_active\n",
    "\n",
    "    # 1) Request streaming MP3 from ElevenLabs\n",
    "    url = f\"https://api.elevenlabs.io/v1/text-to-speech/{VOICE_ID}/stream\"\n",
    "    headers = {\n",
    "        \"xi-api-key\": ELEVEN_LABS_API_KEY,\n",
    "        \"accept\": \"audio/mpeg\"\n",
    "    }\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        headers=headers,\n",
    "        json={\"text\": text, \"model_id\": MODEL_ID},\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    if not response.ok:\n",
    "        print(\"TTS Error:\", response.text)\n",
    "        return False\n",
    "\n",
    "    # 2) Save MP3 to temp file, then convert to WAV\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False) as mp3_file:\n",
    "        for chunk in response.iter_content(chunk_size=4096):\n",
    "            mp3_file.write(chunk)\n",
    "\n",
    "    wav_file = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False)\n",
    "    subprocess.run(\n",
    "        [\"ffmpeg\", \"-y\", \"-i\", mp3_file.name, wav_file.name],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE\n",
    "    )\n",
    "\n",
    "    # 3) Read WAV into numpy array\n",
    "    audio, orig_fs = sf.read(wav_file.name)\n",
    "    # If stereo, convert to mono by averaging\n",
    "    if audio.ndim == 2 and audio.shape[1] == 2:\n",
    "        audio = audio.mean(axis=1)\n",
    "    audio = audio.astype(np.float32)\n",
    "    playback_fs = orig_fs\n",
    "\n",
    "    interrupted = threading.Event()\n",
    "\n",
    "    # 4) Playback function that writes small chunks to OutputStream\n",
    "    def play_audio_in_chunks():\n",
    "        chunk_duration_s = 0.1  # play 100 ms at a time\n",
    "        chunk_size = int(playback_fs * chunk_duration_s)\n",
    "        idx = 0\n",
    "        chunks_played = 0\n",
    "\n",
    "        with sd.OutputStream(samplerate=playback_fs, channels=1, dtype=\"float32\") as out_strm:\n",
    "            while idx < len(audio) and not stop_playback.is_set():\n",
    "                end = min(idx + chunk_size, len(audio))\n",
    "                segment = audio[idx:end]\n",
    "                out_strm.write(segment)\n",
    "                idx = end\n",
    "                chunks_played += 1\n",
    "                # Debug-print every 10 chunks (~1 second if chunk_duration_s=0.1)\n",
    "                if chunks_played % 10 == 0:\n",
    "                    print(f\"[TTS] Played {chunks_played} chunks \"\n",
    "                          f\"({chunks_played * chunk_duration_s:.1f}s)\")\n",
    "\n",
    "    # 5) VAD monitoring thread to detect user speech and interrupt\n",
    "    def monitor_interrupt():\n",
    "        vad_sample_rate = 16000\n",
    "        vad = webrtcvad.Vad(2)\n",
    "        frame_duration_ms = 30\n",
    "        frame_length = int(vad_sample_rate * frame_duration_ms / 1000)\n",
    "\n",
    "        try:\n",
    "            with sd.InputStream(\n",
    "                samplerate=vad_sample_rate,\n",
    "                channels=1,\n",
    "                dtype=\"float32\",\n",
    "                blocksize=frame_length\n",
    "            ) as in_strm:\n",
    "                print(\"[TTS] Monitoring for interrupts\")\n",
    "                while not stop_playback.is_set() and not interrupted.is_set():\n",
    "                    frame, overflow = in_strm.read(frame_length)\n",
    "                    if overflow:\n",
    "                        continue\n",
    "                    audio_chunk = frame[:, 0]\n",
    "                    if np.abs(audio_chunk).mean() < 0.333333:\n",
    "                        continue\n",
    "                    pcm = (audio_chunk * 32767).astype(np.int16).tobytes()\n",
    "                    if len(pcm) != frame_length * 2:\n",
    "                        continue\n",
    "                    try:\n",
    "                        is_speech = vad.is_speech(pcm, vad_sample_rate)\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                    if is_speech:\n",
    "                        print(\"Interrupt detected during TTS\")\n",
    "                        interrupted.set()\n",
    "                        stop_playback.set()\n",
    "                        try:\n",
    "                            sd.stop()\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                        break\n",
    "        except Exception as e:\n",
    "            if not stop_playback.is_set() and not interrupted.is_set():\n",
    "                print(\"Interrupt monitor error:\", e)\n",
    "\n",
    "    # 6) Clear any old flags so neither thread quits instantly\n",
    "    stop_playback.clear()\n",
    "    interrupted.clear()\n",
    "    tts_active.set()\n",
    "\n",
    "    play_thread = threading.Thread(target=play_audio_in_chunks, daemon=True)\n",
    "    listen_thread = threading.Thread(target=monitor_interrupt, daemon=True)\n",
    "\n",
    "    print(\"[TTS] Playback started\")\n",
    "    play_thread.start()\n",
    "    # Give the output stream ~50 ms to queue up at least one chunk before VAD runs\n",
    "    time.sleep(0.05)\n",
    "    listen_thread.start()\n",
    "\n",
    "    # 7) Wait for playback to finish or be interrupted\n",
    "    play_thread.join()\n",
    "    stop_playback.set()\n",
    "    listen_thread.join()\n",
    "    tts_active.clear()\n",
    "\n",
    "    print(\"[TTS] Playback finished\")\n",
    "\n",
    "    # 8) Clean up temp files\n",
    "    try:\n",
    "        os.unlink(mp3_file.name)\n",
    "        os.unlink(wav_file.name)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    return interrupted.is_set()\n",
    "\n",
    "def record_with_vad(fs=16000, frame_duration_ms=30, silence_limit_sec=3, idle_limit_sec=10):\n",
    "    \"\"\"\n",
    "    Records audio using VAD. Returns concatenated numpy array of speech frames,\n",
    "    or None if idle timeout.\n",
    "    \"\"\"\n",
    "    vad = webrtcvad.Vad(2)\n",
    "    frame_length = int(fs * frame_duration_ms / 1000)\n",
    "    silence_threshold = int(silence_limit_sec * 1000 / frame_duration_ms)\n",
    "    idle_threshold = int(idle_limit_sec * 1000 / frame_duration_ms)\n",
    "\n",
    "    print(\"Listening... Speak when ready. (Pause for 3s to process, idle 5s to exit)\")\n",
    "\n",
    "    speech_buffer = []\n",
    "    silence_counter = 0\n",
    "    idle_counter = 0\n",
    "    recording_started = False\n",
    "\n",
    "    try:\n",
    "        with sd.InputStream(samplerate=fs, channels=1, dtype='float32', blocksize=frame_length) as stream:\n",
    "            while True:\n",
    "                frame, overflow = stream.read(frame_length)\n",
    "                if overflow:\n",
    "                    print(\"Audio overflow, skipping frame.\")\n",
    "                    continue\n",
    "\n",
    "                audio = frame[:, 0].copy()\n",
    "                volume = np.abs(audio).mean()\n",
    "                pcm_frame = (audio * 32767).astype(np.int16).tobytes()\n",
    "                is_speech = vad.is_speech(pcm_frame, fs) if volume >= 0.25 else False\n",
    "\n",
    "                if volume < 0.25 and not is_speech and not recording_started:\n",
    "                    print(f\"Low volume ({volume:.5f}) and no speech — frame ignored\")\n",
    "                    # continue\n",
    "\n",
    "                if is_speech:\n",
    "                    print(\"Speech detected\")\n",
    "                    if not recording_started:\n",
    "                        print(\"Speech started.\")\n",
    "                    recording_started = True\n",
    "                    silence_counter = 0\n",
    "                    idle_counter = 0\n",
    "                    speech_buffer.append(audio)\n",
    "\n",
    "                elif recording_started:\n",
    "                    silence_counter += 1\n",
    "                    speech_buffer.append(audio)\n",
    "                    print(f\"Silence {silence_counter}/{silence_threshold} after speech\")\n",
    "                    if silence_counter > silence_threshold:\n",
    "                        print(\"Speech ended. Sending to transcription.\")\n",
    "                        return np.concatenate(speech_buffer)\n",
    "                else:\n",
    "                    print(\"Silence(no speech yet)\")\n",
    "                    if not tts_active.is_set():\n",
    "                        idle_counter += 1\n",
    "                        print(f\"Idle {idle_counter}/{idle_threshold} (no speech yet)\")\n",
    "                        if idle_counter > idle_threshold:\n",
    "                            print(\"Idle timeout. No speech detected.\")\n",
    "                            sys.exit(0)\n",
    "                            return None\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopped by user.\")\n",
    "        return None\n",
    "\n",
    "def elevenlabs_stt(audio_data, fs=16000):\n",
    "    \"\"\"\n",
    "    Sends a numpy array of audio (fs=16000) to ElevenLabs STT and returns transcribed text.\n",
    "    \"\"\"\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp:\n",
    "        sf.write(tmp.name, audio_data, fs)\n",
    "        url = \"https://api.elevenlabs.io/v1/speech-to-text\"\n",
    "        headers = {\"xi-api-key\": ELEVEN_LABS_API_KEY}\n",
    "        with open(tmp.name, \"rb\") as f:\n",
    "            response = requests.post(url, headers=headers, files={\"file\": f}, data={\"model_id\": \"scribe_v1\"})\n",
    "        os.unlink(tmp.name)\n",
    "        if response.ok:\n",
    "            return response.json().get(\"text\", \"\")\n",
    "        else:\n",
    "            print(\"STT Error:\", response.text)\n",
    "            return \"\"\n",
    "\n",
    "def get_llm_response(prompt):\n",
    "    \"\"\"\n",
    "    Queries OpenAI GPT-3.5-turbo with a professional, efficient prompt and returns the assistant's reply.\n",
    "    If the user input appears to be non-English or unintelligible (“gibberish”), returns an empty string.\n",
    "    \"\"\"\n",
    "    # Precheck: if input is clearly not English or seems like noise, return empty\n",
    "    # (Here we use a simple heuristic: if the prompt has fewer than 5 alphabetic characters, treat as noise.\n",
    "    #  You can replace this with a more robust language-detection check if desired.)\n",
    "    if sum(c.isalpha() for c in prompt) < 5:\n",
    "        return \"\"\n",
    "\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are a professional, concise, and highly efficient assistant. But always response in English, doesn't matter in which language user speaks. \"\n",
    "                    \"Always respond in clear, well-structured English, using no more than 20 words unless absolutely necessary. \"\n",
    "                )\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "def conversation_loop(cases, embeddings_model, embeddings):\n",
    "    \"\"\"\n",
    "    Main loop: records user speech, transcribes it, gets LLM response, plays TTS, and restarts on interruption.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        audio_data = record_with_vad()\n",
    "        if audio_data is None:\n",
    "            continue\n",
    "\n",
    "        text = elevenlabs_stt(audio_data)\n",
    "        if not text.strip():\n",
    "            continue\n",
    "\n",
    "        prompt = text\n",
    "        response_text = get_llm_response(prompt)\n",
    "        print(f\"Agent: {response_text}\")\n",
    "        print(\"ENABLE TTS \", ENABLE_TTS)\n",
    "\n",
    "        if ENABLE_TTS:\n",
    "            interrupted = elevenlabs_stream_tts(response_text[:MAX_TTS_CHARACTERS])\n",
    "            if interrupted:\n",
    "                print(\"[Main] TTS interrupted by user speech. Restarting listening loop...\")\n",
    "                time.sleep(0.3)  # Allow the audio device to recover\n",
    "                try:\n",
    "                    sd.stop()\n",
    "                except Exception as e:\n",
    "                    print(\"Error stopping sounddevice:\", e)\n",
    "                continue  # Go back to listening immediately 7 bje jana tha\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cases = []\n",
    "    embeddings = np.array([])\n",
    "    embeddings_model = None\n",
    "    conversation_loop(cases, embeddings_model, embeddings)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
