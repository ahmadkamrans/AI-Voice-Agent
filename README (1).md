
# Voice AI Agent (Node.js)

This is a real-time voice AI agent using:
- **Telnyx** for voice call routing and audio streaming
- **ElevenLabs** for speech-to-text (STT) and text-to-speech (TTS)
- **OpenAI (GPT + RAG)** for conversational intelligence
- **pgvector** for context-aware responses
- **Redis + BullMQ** for scalable concurrent processing

---

## ğŸ“¦ Project Structure

```
voice_ai_agent/
â”œâ”€â”€ server.js         # Main server: handles voice, AI, audio
â”œâ”€â”€ test-client.js    # Local microphone test client
â”œâ”€â”€ .env.example      # Environment variables template
â””â”€â”€ public/           # Stores generated MP3 files
```

---

## ğŸš€ How It Works (Call Flow)

1. User **calls your Telnyx number**.
2. Telnyx triggers `/webhooks/voice`, and the call is answered.
3. A **real-time audio stream** starts via WebSocket.
4. Audio is sent to **ElevenLabs STT** and transcribed.
5. Transcribed text is passed to **OpenAI GPT**, with **pgvector context retrieval**.
6. AI response is converted to **speech using ElevenLabs TTS**.
7. MP3 is **played back to the caller** via Telnyx's `actions/play`.
8. This loop continues as long as the caller stays connected.

---

## ğŸ§  AI Logic: LangChain-Style RAG

- Transcription is embedded via `text-embedding-ada-002`.
- pgvector performs similarity search from `documents` table.
- Relevant context is injected into the GPT chat for improved answers.

---

## ğŸ“‚ Key Files & Functions

### `server.js`

- **`/webhooks/voice`**
  - Accepts Telnyx call and starts audio stream
- **`wss.on('connection')`**
  - Handles WebSocket stream, buffers audio until `__END__` is sent
- **`voiceQueue`**
  - Redis queue using BullMQ to handle each user session independently
- **`transcribeAudio(buffer)`**
  - Sends audio to ElevenLabs STT and returns the transcript
- **`fetchContextFromPgVector(query)`**
  - Gets nearest context from your `documents` table
- **`askOpenAIWithContext(transcript, context)`**
  - Passes user input + context to OpenAI GPT
- **`synthesizeSpeech(text)`**
  - Uses ElevenLabs to turn GPT response into speech (MP3)

### `test-client.js`

- Streams mic audio to WebSocket server
- Sends `__END__` after silence
- Allows testing without phone call

---

## âš™ï¸ Environment Setup

Copy `.env.example` to `.env` and fill in:
```
OPENAI_API_KEY=
ELEVENLABS_API_KEY=
TELNYX_API_KEY=
DATABASE_URL=
BASE_URL=http://localhost:3000
BASE_WS_URL=ws://localhost:3000
REDIS_URL=redis://localhost:6379
```

---

## ğŸ§ª Run the App

1. Start Redis and PostgreSQL
2. Start the voice server:
```bash
node server.js
```

3. Run test client:
```bash
node test-client.js
```

---

## ğŸ” Real-Time Conversation

Each turn:
- Audio â†’ Transcription â†’ Context + GPT â†’ Speech â†’ Telnyx Playback

You can keep talking and getting replies â€” itâ€™s a natural loop.

---

## ğŸ³ Docker (Optional)

Coming soon: Dockerfile + Compose for Redis, Node, Postgres.

---

## ğŸ“ Scaling

- Horizontally scale using PM2 or Docker swarm
- BullMQ + Redis ensure workers can process 1000+ concurrent calls

---

## ğŸ“„ License

MIT
